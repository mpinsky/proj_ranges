abline(v=reefs)
abline(v=reefs, col='red')
sd(l[keep])
reefs2 = runif(10,0,100)
keep2 = rep(FALSE, length(l)); for(i in 1:length(reefs2)) keep2 = keep2 | (abs(l-reefs2[i]) < 1)
hist(l[keep2])
abline(v=reefs2, col='red')
hist(l[keep2], breaks=100)
abline(v=reefs2, col='red')
sd(l[keep2])
sds = rep(NA, 100)
l = rnorm(10000, mean=50, sd=10)
for(i in 1:length(sds)){	reefs = runif(10, 0, 100)	keep = rep(FALSE, length(l)); for(j in 1:length(reefs)) keep = keep | (abs(l-reefs[j]) < 1)	sds[i] = sd(l[keep])}
summary(sds)
hist(sds)
sds = rep(NA, 100)reefs = runif(10, 0, 100)
for(i in 1:length(sds)){	l = rnorm(1000, mean=50, sd=10)	keep = rep(FALSE, length(l)); for(j in 1:length(reefs)) keep = keep | (abs(l-reefs[j]) < 1)	sds[i] = sd(l[keep])}summary(sds)
hist(sds)
sds = rep(NA, 1000)reefs = runif(10, 0, 100)for(i in 1:length(sds)){	l = rnorm(1000, mean=50, sd=10)	keep = rep(FALSE, length(l)); for(j in 1:length(reefs)) keep = keep | (abs(l-reefs[j]) < 1)	sds[i] = sd(l[keep])}summary(sds)hist(sds)
for(i in 1:length(sds)){	l = rnorm(1000, mean=50, sd=10)	keep = rep(FALSE, length(l)); for(j in 1:length(reefs)) keep = keep | (abs(l-reefs[j]) < 1)	sds[i] = sd(l[keep])}summary(sds)hist(sds)
7000/5/2
sqrt(700)
sqrt(600)
sqrt(850)
1126/120
sqrt(c(6000, 7000, 8500)/2/9)
sqrt(c(6000, 7000, 8500)/2/5)
library(RColorBrewer)mq = c(1,1) # manmade capital quantitymp = c(1, 0.8) # pricehq = c(1,1) # human capital quantityhp = c(1, 0.4)nq = c(1,0.6) # natural capital quantitynp = c(1, 1.25)quartz(width=7,height=4)par(mfrow=c(1,2))
cols = brewer.pal(6, 'Paired')
t = c(0,1)
par(mfrow=c(1,2))
plot(t, mq, col=cols[1], type='o')
par(mfrow=c(1,2))plot(t, mq, col=cols[1], type='o', ylim=ylims)
ylims = c(0,1.1)
par(mfrow=c(1,2))plot(t, mq, col=cols[1], type='o', ylim=ylims)
par(mfrow=c(1,2))plot(t, mq, col=cols[1], type='o', ylim=ylims, pch=16)
lines(t,hq, col=cols[2], type='o', pch=16)
mq
hq
mq = c(1.05,1.05) # manmade capital quantitymp = c(1, 0.8) # pricehq = c(1,1) # human capital quantityhp = c(1, 0.4)nq = c(0.95,0.6) # natural capital quantitynp = c(1, 1.25)t = c(0,1)
par(mfrow=c(1,2))plot(t, mq, col=cols[1], type='o', ylim=ylims, pch=16)lines(t,hq, col=cols[2], type='o', pch=16)
lines(t,nq, col=cols[3], type='o', pch=16)
par(mfrow=c(1,2), las=2)plot(t, mq, col=cols[1], type='o', ylim=ylims, pch=16)lines(t,hq, col=cols[2], type='o', pch=16)lines(t,nq, col=cols[3], type='o', pch=16)
par(mfrow=c(1,2), las=2)plot(t, mq, col=cols[1], type='o', ylim=ylims, pch=16)lines(t,hq, col=cols[3], type='o', pch=16)lines(t,nq, col=cols[5], type='o', pch=16)
plot(t, mp, col=cols[2], type='o', ylim=ylims, pch=16)lines(t,hp, col=cols[4], type='o', pch=16)lines(t,np, col=cols[6], type='o', pch=16)
ylims = c(0,1.3)
par(mfrow=c(1,2), las=2)plot(t, mq, col=cols[1], type='o', ylim=ylims, pch=16)lines(t,hq, col=cols[3], type='o', pch=16)lines(t,nq, col=cols[5], type='o', pch=16)plot(t, mp, col=cols[2], type='o', ylim=ylims, pch=16)lines(t,hp, col=cols[4], type='o', pch=16)lines(t,np, col=cols[6], type='o', pch=16)
par(mfrow=c(1,3), las=2)plot(t, mq, col=cols[1], type='o', ylim=ylims, pch=16, ylab='Quantity')lines(t,hq, col=cols[3], type='o', pch=16)lines(t,nq, col=cols[5], type='o', pch=16)plot(t, mp, col=cols[1], type='o', ylim=ylims, pch=16, ylab='Price')lines(t,hp, col=cols[3], type='o', pch=16)lines(t,np, col=cols[5], type='o', pch=16)plot(t, mp*mq, col=cols[1], type='o', ylim=ylims, pch=16, ylab='Value')lines(t,hp*hq, col=cols[3], type='o', pch=16)lines(t,np*nq, col=cols[5], type='o', pch=16)
quartz(width=9,height=4)par(mfrow=c(1,3), las=2)plot(t, mq, col=cols[1], type='o', ylim=ylims, pch=16, ylab='Quantity')lines(t,hq, col=cols[3], type='o', pch=16)lines(t,nq, col=cols[5], type='o', pch=16)plot(t, mp, col=cols[1], type='o', ylim=ylims, pch=16, ylab='Price')lines(t,hp, col=cols[3], type='o', pch=16)lines(t,np, col=cols[5], type='o', pch=16)plot(t, mp*mq, col=cols[1], type='o', ylim=ylims, pch=16, ylab='Value')lines(t,hp*hq, col=cols[3], type='o', pch=16)lines(t,np*nq, col=cols[5], type='o', pch=16)
quartz(width=6,height=3)par(mfrow=c(1,3), las=2)plot(t, mq, col=cols[1], type='o', ylim=ylims, pch=16, ylab='Quantity')lines(t,hq, col=cols[3], type='o', pch=16)lines(t,nq, col=cols[5], type='o', pch=16)plot(t, mp, col=cols[1], type='o', ylim=ylims, pch=16, ylab='Price')lines(t,hp, col=cols[3], type='o', pch=16)lines(t,np, col=cols[5], type='o', pch=16)plot(t, mp*mq, col=cols[1], type='o', ylim=ylims, pch=16, ylab='Value')lines(t,hp*hq, col=cols[3], type='o', pch=16)lines(t,np*nq, col=cols[5], type='o', pch=16)
?par
par(mfrow=c(1,3), las=1, mai=c(0.5)plot(t, mq, col=cols[1], type='o', ylim=ylims, pch=16, ylab='Quantity')lines(t,hq, col=cols[3], type='o', pch=16)lines(t,nq, col=cols[5], type='o', pch=16)plot(t, mp, col=cols[1], type='o', ylim=ylims, pch=16, ylab='Price')lines(t,hp, col=cols[3], type='o', pch=16)lines(t,np, col=cols[5], type='o', pch=16)plot(t, mp*mq, col=cols[1], type='o', ylim=ylims, pch=16, ylab='Value')lines(t,hp*hq, col=cols[3], type='o', pch=16)lines(t,np*nq, col=cols[5], type='o', pch=16)
quartz(width=6,height=3)par(mfrow=c(1,3), las=1, mai=c(0.5)plot(t, mq, col=cols[1], type='o', ylim=ylims, pch=16, ylab='Quantity')lines(t,hq, col=cols[3], type='o', pch=16)lines(t,nq, col=cols[5], type='o', pch=16)plot(t, mp, col=cols[1], type='o', ylim=ylims, pch=16, ylab='Price')lines(t,hp, col=cols[3], type='o', pch=16)lines(t,np, col=cols[5], type='o', pch=16)plot(t, mp*mq, col=cols[1], type='o', ylim=ylims, pch=16, ylab='Value')lines(t,hp*hq, col=cols[3], type='o', pch=16)lines(t,np*nq, col=cols[5], type='o', pch=16)
quartz(width=6,height=3)par(mfrow=c(1,3), las=1, mai=c(0.5, 0.5, 0.2, 0.1))plot(t, mq, col=cols[1], type='o', ylim=ylims, pch=16, ylab='Quantity')lines(t,hq, col=cols[3], type='o', pch=16)lines(t,nq, col=cols[5], type='o', pch=16)plot(t, mp, col=cols[1], type='o', ylim=ylims, pch=16, ylab='Price')lines(t,hp, col=cols[3], type='o', pch=16)lines(t,np, col=cols[5], type='o', pch=16)plot(t, mp*mq, col=cols[1], type='o', ylim=ylims, pch=16, ylab='Value')lines(t,hp*hq, col=cols[3], type='o', pch=16)lines(t,np*nq, col=cols[5], type='o', pch=16)
x=rpois(1000, 10)
hist(x)
hist(x, breaks=c(0,30,by=1))
hist(x, breaks=seq(0,30,by=1))
hist(x, breaks=seq(-0.5,30,by=1))
hist(rpois(10000,10), breaks=seq(-0.5,30,by=1), col='grey')
hist(rpois(10000,5), breaks=seq(-0.5,30,by=1), col='grey')
hist(rpois(10000,3), breaks=seq(-0.5,30,by=1), col='grey')
hist(rpois(10000,4), breaks=seq(-0.5,30,by=1), col='grey')
hist(rpois(10000,5), breaks=seq(-0.5,30,by=1), col='grey')
x = rpois(100, 0.25)/100
hist(x, col='grey')
?rpois
x= rgeom(100,0.25)/100
hist(x, col='grey')
x[1:10]
x = rbinom(1000, 100, 0.25)
x[1:10]
x = rbinom(1000, 100, 0.25)/100
x[1:10]
hist(x, col='grey')
abline(v=0.33)
sum(x>=0.33)/length(x)
x = rbinom(1000, 50, 0.25)/100
hist(x, col='grey')
abline(v=0.33)
x = rbinom(10000, 50, 0.25)/50
hist(x, col='grey')
abline(v=0.33)
sum(x>=0.33)/length(x)
x = rbinom(1000000, 100, 0.25)/100
hist(x, col='grey')
sum(x>=0.33)/length(x)
x = rbinom(1000000, 50, 0.25)/50
sum(x>=0.33)/length(x)
Correlations among variables?
la = 1:100
fa = 4.7559*la^2.6399
plot(la, fa)
biomassave = dara.frame(region = rep(myregions, c(80,80)), year = rep(2020:2099, 2)) # total abundance (2020-2099) for
runtype <- 'testseason'############################## Choose species to project ##############################load(paste('output/modeldiag_', runtype, '.Rdata', sep='')) # model diagnosticsprojspp <- modeldiag$sppocean[modeldiag$auc.tt >= 0.75 & !is.na(modeldiag$auc.tt)] # from Elith et al., but there may be better criteria to uselength(projspp) # number of species to project to# find the files with these species for our chosen model fitfiles <- list.files(modfolder)files <- files[grepl(paste('_', runtype, '_', sep=''), files) & grepl(paste(gsub('/|\\(|\\)', '', projspp), collapse='|'), gsub('/|\\(|\\)', '', files))] # have to strip out parentheses and slashes from file and taxon names so that grep doesn't interpret themlength(files) # should match length of projspp
options(warn=1) # print warnings as they occur
load('~/Documents/Rutgers/NorthAmerican_survey_data/NEFSC/2015-01-30/Survdat.RData')
ls()
head(survdat)
t = 1:100
x = sin(t/10)
plot(t,x)
x = sin(t/30) + rnorm
x = sin(t/30) + rnorm(length(t))
plot(t,x, type='l')
x = sin(t/30) + rnorm(length(t), sd=0.3)
plot(t,x, type='l')
x = sin(t/5) + rnorm(length(t))
plot(t,x, type='l')
x = sin(t/5) + rnorm(length(t), sd=0.3)
plot(t,x, type='l')
x = sin(t/6) + rnorm(length(t), sd=0.3)
plot(t,x, type='l')
x = sin(t/6) +0.5*cos(t/10)+ rnorm(length(t), sd=0.3)
plot(t,x, type='l')
plot(t,x, type='l', bty='n', xaxt='n', yaxt='n')
plot(t,x, type='l', bty='n', xaxt='n', yaxt='n', lwd=2)
plot(t,x, type='l', bty='n', xaxt='n', yaxt='n', lwd=3)
x = sin(t/6) +0.6*cos(t/10)+ rnorm(length(t), sd=0.3)
plot(t,x, type='l', bty='n', xaxt='n', yaxt='n', lwd=3)
x = sin(t/6) +0.6*cos(t/15)+ rnorm(length(t), sd=0.3)
plot(t,x, type='l', bty='n', xaxt='n', yaxt='n', lwd=3)
y = x + 0.02*t
plot(t,y, type='l', bty='n', xaxt='n', yaxt='n', lwd=3)
y = x + 0.2*t
plot(t,y, type='l', bty='n', xaxt='n', yaxt='n', lwd=3)
range(x)
plot(t,x, type='l', bty='n', xaxt='n', yaxt='n', lwd=3, ylim=c(-2,5))
plot(t,x, type='l', bty='n', xaxt='n', yaxt='n', lwd=3, ylim=c(-2,6))
y = x + t/20
lines(t,y)
y = x + t/15
lines(t,y)
plot(t,x, type='l', bty='n', xaxt='n', yaxt='n', lwd=3, ylim=c(-2,8))
lines(t,y)
y = x + t/12
plot(t,x, type='l', bty='n', xaxt='n', yaxt='n', lwd=3, ylim=c(-2,8))
lines(t,y)
plot(t,x, type='l', bty='n', xaxt='n', yaxt='n', lwd=3, ylim=c(-2,10))
lines(t,y)
plot(t,x, type='l', bty='n', xaxt='n', yaxt='n', lwd=3, ylim=c(-2,10))
plot(t,x, type='l', bty='n', xaxt='n', yaxt='n', lwd=3, ylim=c(-2,10), col='white')
plot(t,x, type='l', bty='n', xaxt='n', yaxt='n', lwd=3, ylim=c(-2,10), col='white', bg='black')
plot(t,x, type='l', bty='n', xaxt='n', yaxt='n', lwd=3, ylim=c(-2,10), col='white', xlab='', ylab='')
plot(t,y, type='l', bty='n', xaxt='n', yaxt='n', lwd=3, ylim=c(-2,10), col='white', xlab='', ylab='')
sigma <- 18 # kmTsp = 365 # duration of spawning seasonTL = 3 # time scale for settlement events (eddy duration)C = 225 # coastline lengthr = 25 # settlement event scale (eddy size)P = Tsp/TL*C/r
P
P = Tsp/TL*C/r*fsv
P
fsv = 0.01P = Tsp/TL*C/r*fsv
P
?sample
i=1
n = 100sigma_est = numeric(n)
sigma <- 18 # kmnlarv = 400 # number of larvae sampled each yearTsp = 365 # duration of spawning seasonTL = 3 # time scale for settlement events (eddy duration)C = 225 # coastline lengthr = 25 # settlement event scale (eddy size)fsv = 0.01 # fraction of eddies with larvaeP = round(Tsp/TL*C/r*fsv) # number of eddies per season
yks = rep(0, P) # source	xks = rnorm(P, mean = 0, sd = sigma) # destination
xks
packets = sample(1:P, size=nlarv)
packets = sample(1:P, size=nlarv, replace=TRUE)
packets
j=1
sum(packets==j)
xks_larv[packets == j]
xks_larv = numeric(nlarv) # destinations of individual larvae
xks_larv[packets == j]
xks_larv = rep(NA, nlarv) # destinations of individual larvae
xks_larv[packets == j]
xks_larv[packets == j] = runif(sum(packets==j), min=xks[j]-r/2, max=xks[j]+r/2)
xks_larv[packets == j]
for(j in 1:P){ # for each packet		xks_larv[packets == j] = runif(sum(packets==j), min=xks[j]-r/2, max=xks[j]+r/2)	}
xks_larv
hist(xks_larv)
sd(xks_larv)
n = 100sigma_est = numeric(n)for(i in 1:n){	yks = rep(0, P) # sources are at 0 for simplicity	xks = rnorm(P, mean = 0, sd = sigma) # destination of packet centers	packets = sample(1:P, size=nlarv, replace=TRUE) # which packet each larva is in	xks_larv = rep(NA, nlarv) # destinations of individual larvae	for(j in 1:P){ # for each packet		xks_larv[packets == j] = runif(sum(packets==j), min=xks[j]-r/2, max=xks[j]+r/2)	}	sigma_est[i] = sd(xks_larv)}
hist(sigma_est)
n = 1000sigma_est = numeric(n)for(i in 1:n){	yks = rep(0, P) # sources are at 0 for simplicity	xks = rnorm(P, mean = 0, sd = sigma) # destination of packet centers	packets = sample(1:P, size=nlarv, replace=TRUE) # which packet each larva is in	xks_larv = rep(NA, nlarv) # destinations of individual larvae	for(j in 1:P){ # for each packet		xks_larv[packets == j] = runif(sum(packets==j), min=xks[j]-r/2, max=xks[j]+r/2)	}	sigma_est[i] = sd(xks_larv)}hist(sigma_est)
n = 10000sigma_est = numeric(n)for(i in 1:n){	yks = rep(0, P) # sources are at 0 for simplicity	xks = rnorm(P, mean = 0, sd = sigma) # destination of packet centers	packets = sample(1:P, size=nlarv, replace=TRUE) # which packet each larva is in	xks_larv = rep(NA, nlarv) # destinations of individual larvae	for(j in 1:P){ # for each packet		xks_larv[packets == j] = runif(sum(packets==j), min=xks[j]-r/2, max=xks[j]+r/2)	}	sigma_est[i] = sd(xks_larv)}hist(sigma_est)
hist(sigma_est, breaks=20, col='grey')
abline(v=c(27,35), col='red')
sigma <- 18 # kmnlarv = 400 # number of larvae sampled each yearTsp = 365 # duration of spawning seasonTL = 3 # time scale for settlement events (eddy duration)C = 225 # coastline lengthr = 25 # settlement event scale (eddy size)fsv = 0.005 # fraction of eddies with larvaeP = round(Tsp/TL*C/r*fsv) # number of eddies per seasonn = 10000sigma_est = numeric(n)for(i in 1:n){	yks = rep(0, P) # sources are at 0 for simplicity	xks = rnorm(P, mean = 0, sd = sigma) # destination of packet centers	packets = sample(1:P, size=nlarv, replace=TRUE) # which packet each larva is in	xks_larv = rep(NA, nlarv) # destinations of individual larvae	for(j in 1:P){ # for each packet		xks_larv[packets == j] = runif(sum(packets==j), min=xks[j]-r/2, max=xks[j]+r/2)	}	sigma_est[i] = sd(xks_larv)}hist(sigma_est, breaks=20, col='grey')abline(v=c(27,35), col='red')
P
sum(sigma_est>27)/length(sigma_est)sum(sigma_est>35)/length(sigma_est)
sigma <- 18 # kmnlarv = 400 # number of larvae sampled each yearTsp = 365 # duration of spawning seasonTL = 3 # time scale for settlement events (eddy duration)C = 225 # coastline length, kmr = 10 # settlement event scale (eddy size), kmfsv = 0.005 # fraction of eddies with larvaeP = round(Tsp/TL*C/r*fsv) # number of eddies per seasonP
fsv = 0.001 # fraction of eddies with larvaeP = round(Tsp/TL*C/r*fsv) # number of eddies per seasonP
n = 10000sigma_est = numeric(n)for(i in 1:n){	yks = rep(0, P) # sources are at 0 for simplicity	xks = rnorm(P, mean = 0, sd = sigma) # destination of packet centers	packets = sample(1:P, size=nlarv, replace=TRUE) # which packet each larva is in	xks_larv = rep(NA, nlarv) # destinations of individual larvae	for(j in 1:P){ # for each packet		xks_larv[packets == j] = runif(sum(packets==j), min=xks[j]-r/2, max=xks[j]+r/2)	}	sigma_est[i] = sd(xks_larv)}hist(sigma_est, breaks=20, col='grey')abline(v=c(27,35), col='red')sum(sigma_est>27)/length(sigma_est) # sum(sigma_est>35)/length(sigma_est)
sigma <- 18 # kmnlarv = 100 # number of larvae sampled each yearTsp = 365 # duration of spawning seasonTL = 3 # time scale for settlement events (eddy duration)C = 225 # coastline length, kmr = 10 # settlement event scale (eddy size), kmfsv = 0.001 # fraction of eddies with larvaeP = round(Tsp/TL*C/r*fsv) # number of eddies per seasonPn = 10000sigma_est = numeric(n)for(i in 1:n){	yks = rep(0, P) # sources are at 0 for simplicity	xks = rnorm(P, mean = 0, sd = sigma) # destination of packet centers	packets = sample(1:P, size=nlarv, replace=TRUE) # which packet each larva is in	xks_larv = rep(NA, nlarv) # destinations of individual larvae	for(j in 1:P){ # for each packet		xks_larv[packets == j] = runif(sum(packets==j), min=xks[j]-r/2, max=xks[j]+r/2)	}	sigma_est[i] = sd(xks_larv)}hist(sigma_est, breaks=20, col='grey')abline(v=c(27,35), col='red')sum(sigma_est>27)/length(sigma_est) # sum(sigma_est>35)/length(sigma_est)
quantile(sigma_est, c(0.025, 0.975)
)
P
sigma <- 18 # kmnlarv = 100 # number of larvae matched to parents each yearTsp = 365 # duration of spawning seasonTL = 20 # time scale for settlement events (eddy duration) (Ji: few days to 10s days)C = 225 # coastline length, kmr = 10 # settlement event scale (eddy size), km (Ji: 10s of kmfsv = 0.01 # fraction of eddies with larvaeP = round(Tsp/TL*C/r*fsv) # number of eddies per seasonP
n = 10000sigma_est = numeric(n)for(i in 1:n){	yks = rep(0, P) # sources are at 0 for simplicity	xks = rnorm(P, mean = 0, sd = sigma) # destination of packet centers	packets = sample(1:P, size=nlarv, replace=TRUE) # which packet each larva is in	xks_larv = rep(NA, nlarv) # destinations of individual larvae	for(j in 1:P){ # for each packet		xks_larv[packets == j] = runif(sum(packets==j), min=xks[j]-r/2, max=xks[j]+r/2)	}	sigma_est[i] = sd(xks_larv)}hist(sigma_est, breaks=20, col='grey')abline(v=c(27,35), col='red')sum(sigma_est>27)/length(sigma_est) # sum(sigma_est>35)/length(sigma_est)quantile(sigma_est, c(0.025, 0.975))
sigma <- 18 # kmnlarv = 100 # number of larvae matched to parents each yearTsp = 365 # duration of spawning seasonTL = 20 # time scale for settlement events (eddy duration) (Ji: few days to 10s days)C = 225 # coastline length, kmr = 10 # settlement event scale (eddy size), km (Ji: 10s of kmfsv = 0.1 # fraction of eddies with larvaeP = round(Tsp/TL*C/r*fsv) # number of eddies per seasonPn = 10000sigma_est = numeric(n)for(i in 1:n){	yks = rep(0, P) # sources are at 0 for simplicity	xks = rnorm(P, mean = 0, sd = sigma) # destination of packet centers	packets = sample(1:P, size=nlarv, replace=TRUE) # which packet each larva is in	xks_larv = rep(NA, nlarv) # destinations of individual larvae	for(j in 1:P){ # for each packet		xks_larv[packets == j] = runif(sum(packets==j), min=xks[j]-r/2, max=xks[j]+r/2)	}	sigma_est[i] = sd(xks_larv)}hist(sigma_est, breaks=20, col='grey')abline(v=c(27,35), col='red')sum(sigma_est>27)/length(sigma_est) # sum(sigma_est>35)/length(sigma_est)quantile(s
igma_est, c(0.025, 0.975))
sigma <- 18 # kmnlarv = 100 # number of larvae matched to parents each yearTsp = 365 # duration of spawning seasonTL = 20 # time scale for settlement events (eddy duration) (Ji: few days to 10s days)C = 225 # coastline length, kmr = 20 # settlement event scale (eddy size), km (Ji: 10s of kmfsv = 0.1 # fraction of eddies with larvaeP = round(Tsp/TL*C/r*fsv) # number of eddies per seasonPn = 10000sigma_est = numeric(n)for(i in 1:n){	yks = rep(0, P) # sources are at 0 for simplicity	xks = rnorm(P, mean = 0, sd = sigma) # destination of packet centers	packets = sample(1:P, size=nlarv, replace=TRUE) # which packet each larva is in	xks_larv = rep(NA, nlarv) # destinations of individual larvae	for(j in 1:P){ # for each packet		xks_larv[packets == j] = runif(sum(packets==j), min=xks[j]-r/2, max=xks[j]+r/2)	}	sigma_est[i] = sd(xks_larv)}hist(sigma_est, breaks=20, col='grey')abline(v=c(27,35), col='red')sum(sigma_est>27)/length(sigma_est) # sum(sigma_est>35)/length(sigma_est)quantile(s
igma_est, c(0.025, 0.975))
n = 5allocs = matrix(NA, nrow=12, ncol=5)for(i in 1:12){	locs = sort(floor(runif(n, 0,25)))	while(any(diff(locs) == 0)){		locs = sort(floor(runif(n, 0,25)))	}	allocs[i,] = locs}allocs
## Set working directoriesif(Sys.info()["nodename"] == "pinsky-macbookair"){	setwd('~/Documents/Rutgers/Range projections/proj_ranges/')	}if(Sys.info()["nodename"] == "amphiprion.deenr.rutgers.edu"){	setwd('~/Documents/range_projections/')	}if(Sys.info()["user"] == "lauren"){	setwd('~/backup/NatCap/proj_ranges/')}
library(mgcv);library(ROCR)runname <- "testK6noSeas"#
load("data/dat_selectedspp.Rdata")
dat$logwtcpue <- log(dat$wtcpue)	dat$survey <- dat$region #keeps NEFSC as two separate surveys in "survey"	dat$surveyfact <-as.factor(dat$survey)	dat$region[dat$region %in% c("NEFSC_NEUSFall","NEFSC_NEUSSpring")] <- "NEFSC_NEUS"	dat$regionfact <- as.factor(dat$region) #NEFSC as one region in "region"
allspp = sort(unique(dat$sppocean))n = rep(NA, length(allspp))modeldiag = data.frame(sppocean=n, npres=n, npres.tr=n, npres.te=n, ntot=n, auc=n, auc.tt=n, r2.biomass=n, r2.biomass.tt=n, r2.all=n, r2.all.tt=n, r2.pres.1deg=n, r2.abun.1deg=n, dev.pres=n, dev.biomass=n,dev.pres.null=n, dev.biomass.null=n, stringsAsFactors=FALSE) # tt is
head(dat)
## Set working directoriesif(Sys.info()["nodename"] == "pinsky-macbookair"){	setwd('~/Documents/Rutgers/Range projections/proj_ranges/')	}if(Sys.info()["nodename"] == "amphiprion.deenr.rutgers.edu"){	setwd('~/Documents/range_projections/')	}if(Sys.info()["user"] == "lauren"){	setwd('~/backup/NatCap/proj_ranges/')}#
# Loop through species and fit models.library(mgcv);library(ROCR)runname <- "testK6noSeas"#
load("data/dat_selectedspp.Rdata")	dat$logwtcpue <- log(dat$wtcpue)	dat$survey <- dat$region #keeps NEFSC as two separate surveys in "survey"	dat$surveyfact <-as.factor(dat$survey)	dat$region[dat$region %in% c("NEFSC_NEUSFall","NEFSC_NEUSSpring")] <- "NEFSC_NEUS"	dat$regionfact <- as.factor(dat$region) #NEFSC as one region in "region"	# if using season	dat$season <- as.factor(c(rep('wi', 3), rep('sp', 3), rep('su', 3), rep('fa', 3))[dat$month])	dat$regseas <- as.factor(paste(dat$region,dat$season,sep="_"))allspp = sort(unique(dat$sppocean))n = rep(NA, length(allspp))modeldiag = data.frame(sppocean=n, npres=n, npres.tr=n, npres.te=n, ntot=n, auc=n, auc.tt=n, r2.biomass=n, r2.biomass.tt=n, r2.all=n, r2.all.tt=n, r2.pres.1deg=n, r2.abun.1deg=n, dev.pres=n, dev.biomass=n,dev.pres.null=n, dev.biomass.null=n, stringsAsFactors=FALSE) # tt is for training/testing model
pdf(file=paste("figures/CEmodelGAMsmooths/GAMs_",runname,".pdf",sep=""),width=6,height=6)options(warn=1) # print warnings as they occurallwarnings = NULL
i=1
fittrain = TRUE	mygam1tt <- mygam2tt <- mygam1 <- mygam2 <- preds <- preds1 <- preds2 <- predstt <- preds1tt <- preds2tt <- NULL	sp<-allspp[i]	print(paste(i,sp, Sys.time()))	mydat<-dat[dat$sppocean==sp,] 	myregions<-unique(mydat$region)	myhauls<-unique(mydat$haulid)	#myocean<-mydat[1,"ocean"]	myseasons<-unique(mydat$season)
ninds<-table(mydat$region[mydat$presfit & complete.cases(mydat[,c("bottemp","surftemp", "rugosity","presfit")])]) # number of presences per region with complete data (inc. surftemp)	myregions <- names(ninds)[ninds >= 10] # require at least 10 presences with complete data to keep a region	mydat <- mydat[mydat$region %in% myregions,]
zs<-dat[!(dat$haulid %in% myhauls) & dat$region %in% myregions,] #extract haulids where this species is missing, but only from regions where this species has at least one record.
matchpos<-match(unique(zs$haulid),zs$haulid) # Extract one record of each haulid	zeros<-zs[matchpos,]	#Add/change relevant columns --> zero catch for target spp.	zeros$spp<-mydat$spp[1]	zeros$sppl<-mydat$sppl[1]	zeros$sppnew<-mydat$sppnew[1]#	zeros$sppregion<-paste(zeros$sppnew,zeros$region,sep="_")	zeros$sppocean<-mydat$sppocean[1] #may need to add "ocean"	zeros$wtcpue<-0	zeros$presfit<-F
#	zeros$sppregion<-paste(zeros$sppnew,zeros$region,sep="_")
mydatw0<-rbind(mydat,zeros) #combine positive hauls with zero hauls
ave.catch.wt<-tapply(mydatw0$wtcpue,list(mydatw0$year,mydatw0$region),mean,na.rm=T)	# transform into a data.frame	if(dim(ave.catch.wt)[2]<2) { # only one region		avecatchyrreg<-cbind(as.data.frame(ave.catch.wt), rep(colnames(ave.catch.wt), dim(ave.catch.wt)[2]), rownames(ave.catch.wt))		colnames(avecatchyrreg)<-c("biomassmean","region","year")	} else { # multiple regions		avecatchyrreg<-cbind(stack(as.data.frame(ave.catch.wt)), rep(rownames(ave.catch.wt), dim(ave.catch.wt)[2]))		colnames(avecatchyrreg)<-c("biomassmean","region","year")	}	spdata<-merge(mydatw0,avecatchyrreg)
spdata<-spdata[complete.cases(spdata[,c("surftemp","bottemp","rugosity","presfit")]),]
spdata<-spdata[order(spdata$year,spdata$month),]	# indices for both pres and abs	ninds<-table(spdata$region) # number of entries per region	traininds <- NULL; testinds <- NULL	for(j in 1:length(ninds)){ # loop through each region to get first 80% and last 20%		traininds <- c(traininds, which(spdata$region == names(ninds)[j])[1:round(ninds[j]*0.8)])		testinds <- c(testinds, which(spdata$region == names(ninds)[j])[(round(ninds[j]*0.8)+1):ninds[j]])	}#
	# indices for only where present (for the abundance model)	trainindsp <- intersect(traininds, which(spdata$presfit))	testindsp <- intersect(testinds, which(spdata$presfit))	if(length(trainindsp)<2){		mywarn <- paste('Only', length(trainindsp), 'presence values in testing dataset for', i, sp)		allwarnings <- c(allwarnings, mywarn)		warning(mywarn)	}	if(length(testindsp)<2){		mywarn <- paste('Only', length(testindsp), 'presence values in testing dataset for', i, sp)		allwarnings <- c(allwarnings, mywarn)		warning(mywarn)	}	# test if we have enough presences in testing and training sets (at least one per region)	nprestrain <- table(spdata$region[trainindsp])	nprestest <- table(spdata$region[testindsp])	if(any(nprestrain < 1)){		mywarn <- paste('Zero training presences for', i, sp, 'in', names(nprestrain)[nprestrain<1])		allwarnings <- c(allwarnings, mywarn)		warning(mywarn)	}	if(any(nprestest < 1)){		mywarn <- paste('Zero testing presences for', i, sp, 'in', names(nprestest)[nprestest<1])		allwarnings <- c(allwarnings, mywarn)		warning(mywarn)	}
levs <- apply(spdata[trainindsp,c('bottemp', 'surftemp', 'logrugosity', 'biomassmean')], 2, FUN=function(x) length(unique(x)))	if(any(levs < 6)){		mywarn <- paste("Not enough (>=6) unique levels in training presence set for", i, sp, ". Won't fit training models")		allwarnings <- c(allwarnings, mywarn)		warning(mywarn)		fittrain = FALSE	}
if(length(myregions)==1){			mypresmod<-formula(presfit ~ s(bottemp,k=6)+s(surftemp,k=6)+s(logrugosity,k=4)+s(biomassmean,k=4))			myabunmod<-formula(logwtcpue ~ s(bottemp,k=6)+s(surftemp,k=6)+s(logrugosity,k=4)+s(biomassmean,k=4))			mynullpresmod<-formula(presfit ~ s(logrugosity,k=4)+s(biomassmean,k=4)) #Null model w/o temp			mynullabunmod<-formula(logwtcpue ~ s(logrugosity,k=4)+s(biomassmean,k=4)) #Null model w/o temp	} else {			mypresmod<-formula(presfit ~ s(bottemp,k=6)+s(surftemp,k=6)+s(logrugosity,k=4)+regionfact+s(biomassmean,k=4)-1)			myabunmod<-formula(logwtcpue ~ s(bottemp,k=6)+s(surftemp,k=6)+s(logrugosity,k=4)+regionfact+s(biomassmean,k=4)-1)			mynullpresmod<-formula(presfit ~ s(logrugosity,k=4)+regionfact+s(biomassmean,k=4)-1) #Null model w/o temp			mynullabunmod<-formula(logwtcpue ~ s(logrugosity,k=4)+regionfact+s(biomassmean,k=4)-1) #Null model w/o temp	}
if(fittrain){		try1 <- tryCatch({			mygam1tt<-gam(mypresmod, family="binomial",data=spdata[traininds,]) 			mygam2tt<-gam(myabunmod, data=spdata[trainindsp,]) # only fit where species is present		}, error = function(e) { # ignore warnings, since no function to catch them			mywarn <- paste('Error in training gam fitting for', i, sp, ':', e)			assign('allwarnings', c(get('allwarnings', envir=.GlobalEnv), mywarn), envir=.GlobalEnv) # these assigns outside the local scope are poor form in R. But not sure how else to do it here...			assign('fittrain', FALSE, envir=.GlobalEnv) # if we hit an error in predictions, we can't calculate performance stats			warning(mywarn)		})	}
try2 <- tryCatch({		mygam1<-gam(mypresmod,family="binomial",data=spdata)		mygam2<-gam(myabunmod,data=spdata[spdata$presfit,]) # only fit where spp is present		mygam1null<-gam(mynullpresmod,family="binomial",data=spdata)		mygam2null<-gam(mynullabunmod,data=spdata[spdata$presfit,]) # only fit where spp is present#
	}, error = function(e) {		mywarn <- paste('Error in gam fitting for', i, sp, ':', e)		assign('allwarnings', c(get('allwarnings', envir=.GlobalEnv), mywarn), envir=.GlobalEnv) # these assigns outside the local scope are poor form in R. But not sure how else to do it here...		warning(mywarn)	})
plot(mygam1,pages=1,scale=0);mtext(paste(sp,"presence"),outer=T,line=-2)	plot(mygam2,pages=1,scale=0);mtext(paste(sp,"abundance"),outer=T,line=-2)
preds1 <- predict(mygam1,spdata,type="response") #can also use mygam1$fitted.values	preds2 <- exp(predict(mygam2, newdata = spdata, type='response')) # abundance predictions	smear = mean(exp(mygam2$residuals)) # smearing estimator for re-transformation bias (see Duan 1983, http://www.herc.research.va.gov/include/page.asp?ID=cost-regression)	preds <- preds1*preds2*smear # adds the bias correction as well	preds[preds<0] = 0	# And for training/testing data set	if(fittrain){		try3 <- tryCatch({			preds1tt <- predict(mygam1tt,spdata[testinds,],type="response") 			preds2tt <- exp(predict(mygam2tt, newdata = spdata[testinds,], type='response'))			smear = mean(exp(mygam2tt$residuals)) # smearing estimator for re-transformation bias (see Duan 1983, http://www.herc.research.va.gov/include/page.asp?ID=cost-regression)			predstt <- preds1tt*preds2tt*smear			predstt[predstt<0] = 0		}, error = function(e) {			assign('fittrain', FALSE, envir=.GlobalEnv) # if we hit an error in predictions, we can't calculate performance stats			mywarn <- paste('Error in predicting to test data for', i, sp, ':', e)			assign('allwarnings', c(get('allwarnings', envir=.GlobalEnv), mywarn), envir=.GlobalEnv) # these assigns outside the local scope are poor form in R. But not sure how else to do it here...			warning(mywarn)		})	}
modeldiag$sppocean[i] = sp	modeldiag$npres[i] = sum(spdata$presfit)	if(fittrain){		modeldiag$npres.tr[i] = sum(spdata$presfit[traininds])		modeldiag$npres.te[i] = sum(spdata$presfit[testinds])	}	modeldiag$ntot[i] = dim(spdata)[1]	# fill in myregions and myseasons too? would be useful for projections	# calculate performance (in part using ROCR)	preds1.rocr = prediction(predictions=as.numeric(preds1), labels=spdata$presfit)	modeldiag$auc[i] = performance(preds1.rocr, 'auc')@y.values[[1]] # area under the ROC curve	if(length(testindsp)>0 & fittrain){ # need presences in the test dataset		preds1tt.rocr = prediction(predictions=as.numeric(preds1tt), labels=spdata$presfit[testinds])		modeldiag$auc.tt[i] = performance(preds1tt.rocr, 'auc')@y.values[[1]] #	}	# could add true skill statistic	modeldiag$r2.biomass[i] = cor(log(preds2[spdata$presfit]), spdata$logwtcpue[spdata$presfit])^2 # correlation of log(biomass) where present	if(length(testindsp)>0 & fittrain) modeldiag$r2.biomass.tt[i] = cor(preds2tt[which(testinds %in% testindsp)], spdata$logwtcpue[testindsp])^2 # only if presences exist in the test dataset	modeldiag$r2.all[i] = cor(preds, spdata$wtcpue)^2 # overall biomass correlation	if(length(testindsp)>0 & fittrain) modeldiag$r2.all.tt[i] = cor(predstt, spdata$wtcpue[testinds])^2 # overall biomass correlation. only makes sense to do this if the species is present at least once in the testing dataset	modeldiag$dev.pres[i] = summary(mygam1)$dev.expl	modeldiag$dev.biomass[i] = summary(mygam2)$dev.expl
head(preds1.rocr)
preds1.rocr
names(preds1.rocr)
length(preds1.rocr)
?performance
?evaluate
??evaluate
performance(preds1.rocr, 'tpr')
a = performance(preds1.rocr, 'tpr')@y.values[[1]] # true positive	b = performance(preds1.rocr, 'fnr')@y.values[[1]] # false negative	c = performance(preds1.rocr, 'fpr')@y.values[[1]] # false pos	d = performance(preds1.rocr, 'tnr')@y.values[[1]] # true neg
max((a*d - b*c)/((a+c)*(b+d)))
max((a*d - b*c)/((a+c)*(b+d)), na.rm=TRUE)
which(is.na(a*d - b*c)/((a+c)*(b+d)))
which(is.na((a*d - b*c)/((a+c)*(b+d))))
modeldiag$tss[i] = 	max((a*d - b*c)/((a+c)*(b+d)), na.rm=TRUE)
length(testindsp)>0 & fittrain
preds1tt.rocr = prediction(predictions=as.numeric(preds1tt), labels=spdata$presfit[testinds])		a = performance(preds1tt.rocr, 'tpr')@y.values[[1]] # true positive		b = performance(preds1tt.rocr, 'fnr')@y.values[[1]] # false negative		c = performance(preds1tt.rocr, 'fpr')@y.values[[1]] # false pos		d = performance(preds1tt.rocr, 'tnr')@y.values[[1]] # true neg
max((a*d - b*c)/((a+c)*(b+d)), na.rm=TRUE)
modeldiag$tss.tt[i] = max((a*d - b*c)/((a+c)*(b+d)), na.rm=TRUE)
modeldiag$r2.biomass[i] = cor(log(preds2[spdata$presfit]), spdata$logwtcpue[spdata$presfit])^2 # correlation of log(biomass) where present	if(length(testindsp)>0 & fittrain) modeldiag$r2.biomass.tt[i] = cor(preds2tt[which(testinds %in% testindsp)], spdata$logwtcpue[testindsp])^2 # only if presences exist in the test dataset	modeldiag$r2.all[i] = cor(preds, spdata$wtcpue)^2 # overall biomass correlation	if(length(testindsp)>0 & fittrain) modeldiag$r2.all.tt[i] = cor(predstt, spdata$wtcpue[testinds])^2 # overall biomass correlation. only makes sense to do this if the species is present at least once in the testing dataset	modeldiag$dev.pres[i] = summary(mygam1)$dev.expl	modeldiag$dev.biomass[i] = summary(mygam2)$dev.expl
modeldiag$dev.pres.null[i] = summary(mygam1null)$dev.expl	modeldiag$dev.biomass.null[i] = summary(mygam2null)$dev.expl	# Some metrics at a spatially aggregated level (1x1deg square) (by year) may be more informative:	test<-cbind(spdata,preds1,preds)	t1<-tapply(test$preds1,list(test$year,test$cs1),mean) #average predicted p(occur)	t2<-tapply(test$presfit,list(test$year,test$cs1),mean) #proportion of hauls with presence	t3<-tapply(test$preds,list(test$year,test$cs1),mean) #average predicted abundance	t4<-tapply(test$wtcpue,list(test$year,test$cs1),mean) #average observed abundance	presr2<-round(cor(stack(as.data.frame(t2))[,1],stack(as.data.frame(t1))[,1],use="p")^2,2)	abunr2<-round(cor(stack(as.data.frame(t4))[,1],(stack(as.data.frame(t3))[,1]),use="p")^2,2)
modeldiag$r2.pres.1deg[i]<-presr2	modeldiag$r2.abun.1deg[i]<-abunr2	#Also save average biomassmean for each region (across all years) to use in later predictions.	avemeanbiomass<-apply(ave.catch.wt,2,mean,na.rm=T) #ave.catch.wt from far above
mods = list(mygam1=mygam1, mygam2 = mygam2)#
	sp <- gsub('/', '', sp) # would mess up saving the file
paste('../CEmodels/CEmods_',runname, '_', sp, '_', Sys.Date(), '.RData', sep='')
if(Sys.info()["nodename"] == "pinsky-macbookair"){		save(mods, avemeanbiomass, myregions, file=paste('../CEmodels/CEmods_',runname, '_', sp, '_', Sys.Date(), '.RData', sep='')) # ~2mb file	}
if(Sys.info()["nodename"] == "amphiprion.deenr.rutgers.edu"){		save(mods, avemeanbiomass, myregions, file=paste('../CEmodels/CEmods_',runname, '_', sp, '_', Sys.Date(), '.RData', sep='')) # ~2mb file	}	if(Sys.info()["user"] == "lauren"){		save(mods, avemeanbiomass, myregions, file=paste('output/CEmodels/CEmods_',runname, '_', sp, '_', Sys.Date(), '.RData', sep='')) # ~2mb file	}
dev.off()save(modeldiag,file=paste("output/modeldiag_",runname,".Rdata",sep=""))write.csv(modeldiag, file=paste("output/modeldiag_",runname,".csv",sep=""))write.csv(allwarnings, file=paste('output/warnings_', runname, '.csv', sep=''))
## Set working directoriesif(Sys.info()["nodename"] == "pinsky-macbookair"){	setwd('~/Documents/Rutgers/Range projections/proj_ranges/')	}if(Sys.info()["nodename"] == "amphiprion.deenr.rutgers.edu"){	setwd('~/Documents/range_projections/')	}if(Sys.info()["user"] == "lauren"){	setwd('~/backup/NatCap/proj_ranges/')}#
# Loop through species and fit models.library(mgcv);library(ROCR)runname <- "testK6noSeas"#
load("data/dat_selectedspp.Rdata")	dat$logwtcpue <- log(dat$wtcpue)	dat$survey <- dat$region #keeps NEFSC as two separate surveys in "survey"	dat$surveyfact <-as.factor(dat$survey)	dat$region[dat$region %in% c("NEFSC_NEUSFall","NEFSC_NEUSSpring")] <- "NEFSC_NEUS"	dat$regionfact <- as.factor(dat$region) #NEFSC as one region in "region"	# if using season	dat$season <- as.factor(c(rep('wi', 3), rep('sp', 3), rep('su', 3), rep('fa', 3))[dat$month])	dat$regseas <- as.factor(paste(dat$region,dat$season,sep="_"))allspp = sort(unique(dat$sppocean))n = rep(NA, length(allspp))modeldiag = data.frame(sppocean=n, npres=n, npres.tr=n, npres.te=n, ntot=n, auc=n, auc.tt=n, tss=n, tss.tt=n, r2.biomass=n, r2.biomass.tt=n, r2.all=n, r2.all.tt=n, r2.pres.1deg=n, r2.abun.1deg=n, dev.pres=n, dev.biomass=n,dev.pres.null=n, dev.biomass.null=n, stringsAsFactors=FALSE) # tt is for training/testing model#
## small test to see which species are only marginally present in Newfoundland or WCAnn surveys#nosurfregions <- c("DFO_NewfoundlandSpring","DFO_NewfoundlandFall","NWFSC_WCAnn")#nsrspp <- sort(unique(dat$sppocean[dat$region %in% nosurfregions])) # spp present in at least one of these regions#length(nsrspp)#length(unique(dat$sppocean))#tab <- table(dat$sppocean[dat$wtcpue>0 & dat$sppocean %in% nsrspp], dat$region[dat$wtcpue>0 & dat$sppocean %in% nsrspp]) # counts presences in all regions#dim(tab)#colnames(tab) <- c('AI', 'EBS', 'GOA', 'WCTri', 'Newf_F', 'Newf_S', 'Scot', 'SoGulf', 'NEUS_F', 'NEUS_S', 'WCAnn', 'GoMex') # shorter column names for easier printing to screen#cmax <- apply(tab, 1, which.max) # region with the most catches#nsrspp2 <- which(!(cmax %in% c(5,6,11))) # index for species that didn't have the highest presence count in Newf or WCAnn#tab[nsrspp2,] # spp like Clupea harengus are common in many places#
####################### Start the big loop ########################Open pdf to print figures pdf(file=paste("figures/CEmodelGAMsmooths/GAMs_",runname,".pdf",sep=""),width=6,height=6)options(warn=1) # print warnings as they occurallwarnings = NULLfor(i in 1:20){#length(allspp)){ 	fittrain = TRUE	mygam1tt <- mygam2tt <- mygam1 <- mygam2 <- preds <- preds1 <- preds2 <- predstt <- preds1tt <- preds2tt <- NULL	sp<-allspp[i]	print(paste(i,sp, Sys.time()))	mydat<-dat[dat$sppocean==sp,] 	myregions<-unique(mydat$region)	myhauls<-unique(mydat$haulid)	#myocean<-mydat[1,"ocean"]	myseasons<-unique(mydat$season)	##############################################################	# Test whether we have enough data in each region and season #	##############################################################	# check each region	ninds<-table(mydat$region[mydat$presfit & complete.cases(mydat[,c("bottemp","surftemp", "rugosity","presfit")])]) # number of presences per region with complete data (inc. surftemp)	myregions <- names(ninds)[ninds >= 10] # require at least 10 presences with complete data to keep a region	mydat <- mydat[mydat$region %in% myregions,]#
	####################################################	# Add records for when there was a haul but no fish	####################################################	# Only expand catches (pad with zeros) in regions where the species has previously been caught.	# without season	zs<-dat[!(dat$haulid %in% myhauls) & dat$region %in% myregions,] #extract haulids where this species is missing, but only from regions where this species has at least one record.	matchpos<-match(unique(zs$haulid),zs$haulid) # Extract one record of each haulid	zeros<-zs[matchpos,]	#Add/change relevant columns --> zero catch for target spp.	zeros$spp<-mydat$spp[1]	zeros$sppl<-mydat$sppl[1]	zeros$sppnew<-mydat$sppnew[1]	zeros$sppocean<-mydat$sppocean[1] #may need to add "ocean"	zeros$wtcpue<-0	zeros$presfit<-FALSE	mydatw0<-rbind(mydat,zeros) #combine positive hauls with zero hauls	##########################################################	# Calculate mean catch per haul by region for this taxon #	##########################################################	# (For true biomass estimate, would need to stratify the mean)	ave.catch.wt<-tapply(mydatw0$wtcpue,list(mydatw0$year,mydatw0$region),mean,na.rm=T)	# transform into a data.frame	if(dim(ave.catch.wt)[2]<2) { # only one region		avecatchyrreg<-cbind(as.data.frame(ave.catch.wt), rep(colnames(ave.catch.wt), dim(ave.catch.wt)[2]), rownames(ave.catch.wt))		colnames(avecatchyrreg)<-c("biomassmean","region","year")	} else { # multiple regions		avecatchyrreg<-cbind(stack(as.data.frame(ave.catch.wt)), rep(rownames(ave.catch.wt), dim(ave.catch.wt)[2]))		colnames(avecatchyrreg)<-c("biomassmean","region","year")	}	spdata<-merge(mydatw0,avecatchyrreg)#
	####################################################	# Trim data to complete cases	####################################################	spdata<-spdata[complete.cases(spdata[,c("surftemp","bottemp","rugosity","presfit")]),] 	####################################################	#Set up data for training and testing to evaluate performance	####################################################	#Subset training and testing data by year (use first 80% from each region to predict last 20% in each region)	spdata<-spdata[order(spdata$year,spdata$month),]	# indices for both pres and abs	ninds<-table(spdata$region) # number of entries per region	traininds <- NULL; testinds <- NULL	for(j in 1:length(ninds)){ # loop through each region to get first 80% and last 20%		traininds <- c(traininds, which(spdata$region == names(ninds)[j])[1:round(ninds[j]*0.8)])		testinds <- c(testinds, which(spdata$region == names(ninds)[j])[(round(ninds[j]*0.8)+1):ninds[j]])	}#
	# indices for only where present (for the abundance model)	trainindsp <- intersect(traininds, which(spdata$presfit))	testindsp <- intersect(testinds, which(spdata$presfit))	if(length(trainindsp)<2){		mywarn <- paste('Only', length(trainindsp), 'presence values in testing dataset for', i, sp)		allwarnings <- c(allwarnings, mywarn)		warning(mywarn)	}	if(length(testindsp)<2){		mywarn <- paste('Only', length(testindsp), 'presence values in testing dataset for', i, sp)		allwarnings <- c(allwarnings, mywarn)		warning(mywarn)	}	# test if we have enough presences in testing and training sets (at least one per region)	nprestrain <- table(spdata$region[trainindsp])	nprestest <- table(spdata$region[testindsp])	if(any(nprestrain < 1)){		mywarn <- paste('Zero training presences for', i, sp, 'in', names(nprestrain)[nprestrain<1])		allwarnings <- c(allwarnings, mywarn)		warning(mywarn)	}	if(any(nprestest < 1)){		mywarn <- paste('Zero testing presences for', i, sp, 'in', names(nprestest)[nprestest<1])		allwarnings <- c(allwarnings, mywarn)		warning(mywarn)	}#
	# make sure we have at least 6 unique levels for each variable (necessary to fit gam with 4 knots)	# look at training presence indices, since the most constraining (for mygam2tt)	# this doesn't test by season... and so wont' catch a season with very few datapoints	levs <- apply(spdata[trainindsp,c('bottemp', 'surftemp', 'logrugosity', 'biomassmean')], 2, FUN=function(x) length(unique(x)))	if(any(levs < 6)){		mywarn <- paste("Not enough (>=6) unique levels in training presence set for", i, sp, ". Won't fit training models")		allwarnings <- c(allwarnings, mywarn)		warning(mywarn)		fittrain = FALSE	}		# table(spdata$year[spdata$presfit]) # output number of presences by year#
	####################################################	# Figure out which model formula given data	####################################################	# without season	#Default models. Leave out region factor if necessary	if(length(myregions)==1){			mypresmod<-formula(presfit ~ s(bottemp,k=6)+s(surftemp,k=6)+s(logrugosity,k=4)+s(biomassmean,k=4))			myabunmod<-formula(logwtcpue ~ s(bottemp,k=6)+s(surftemp,k=6)+s(logrugosity,k=4)+s(biomassmean,k=4))			mynullpresmod<-formula(presfit ~ s(logrugosity,k=4)+s(biomassmean,k=4)) #Null model w/o temp			mynullabunmod<-formula(logwtcpue ~ s(logrugosity,k=4)+s(biomassmean,k=4)) #Null model w/o temp	} else {			mypresmod<-formula(presfit ~ s(bottemp,k=6)+s(surftemp,k=6)+s(logrugosity,k=4)+regionfact+s(biomassmean,k=4)-1)			myabunmod<-formula(logwtcpue ~ s(bottemp,k=6)+s(surftemp,k=6)+s(logrugosity,k=4)+regionfact+s(biomassmean,k=4)-1)			mynullpresmod<-formula(presfit ~ s(logrugosity,k=4)+regionfact+s(biomassmean,k=4)-1) #Null model w/o temp			mynullabunmod<-formula(logwtcpue ~ s(logrugosity,k=4)+regionfact+s(biomassmean,k=4)-1) #Null model w/o temp	}#
	####################################		# Fit the training/testing models	####################################		# We could use select=TRUE so that terms can be smoothed out of the model (a model selection algorithm),	if(fittrain){		try1 <- tryCatch({			mygam1tt<-gam(mypresmod, family="binomial",data=spdata[traininds,]) 			mygam2tt<-gam(myabunmod, data=spdata[trainindsp,]) # only fit where species is present		}, error = function(e) { # ignore warnings, since no function to catch them			mywarn <- paste('Error in training gam fitting for', i, sp, ':', e)			assign('allwarnings', c(get('allwarnings', envir=.GlobalEnv), mywarn), envir=.GlobalEnv) # these assigns outside the local scope are poor form in R. But not sure how else to do it here...			assign('fittrain', FALSE, envir=.GlobalEnv) # if we hit an error in predictions, we can't calculate performance stats			warning(mywarn)		})	}#
	####################################################	#Fit models to All data (no test/training split)	####################################################	try2 <- tryCatch({		mygam1<-gam(mypresmod,family="binomial",data=spdata)		mygam2<-gam(myabunmod,data=spdata[spdata$presfit,]) # only fit where spp is present		mygam1null<-gam(mynullpresmod,family="binomial",data=spdata)		mygam2null<-gam(mynullabunmod,data=spdata[spdata$presfit,]) # only fit where spp is present#
	}, error = function(e) {		mywarn <- paste('Error in gam fitting for', i, sp, ':', e)		assign('allwarnings', c(get('allwarnings', envir=.GlobalEnv), mywarn), envir=.GlobalEnv) # these assigns outside the local scope are poor form in R. But not sure how else to do it here...		warning(mywarn)	})#
	####################################################	# Plot gam smooths to check for unrealistic out-of-range responses 	#####################################################
	#Should write out to PDF	plot(mygam1,pages=1,scale=0);mtext(paste(sp,"presence"),outer=T,line=-2)	plot(mygam2,pages=1,scale=0);mtext(paste(sp,"abundance"),outer=T,line=-2)#
	####################################################	# Compare predictions to observations to assess model performance	####################################################	# For FULL model	preds1 <- predict(mygam1,spdata,type="response") #can also use mygam1$fitted.values	preds2 <- exp(predict(mygam2, newdata = spdata, type='response')) # abundance predictions	smear = mean(exp(mygam2$residuals)) # smearing estimator for re-transformation bias (see Duan 1983, http://www.herc.research.va.gov/include/page.asp?ID=cost-regression)	preds <- preds1*preds2*smear # adds the bias correction as well	preds[preds<0] = 0	# And for training/testing data set	if(fittrain){		try3 <- tryCatch({			preds1tt <- predict(mygam1tt,spdata[testinds,],type="response") 			preds2tt <- exp(predict(mygam2tt, newdata = spdata[testinds,], type='response'))			smear = mean(exp(mygam2tt$residuals)) # smearing estimator for re-transformation bias (see Duan 1983, http://www.herc.research.va.gov/include/page.asp?ID=cost-regression)			predstt <- preds1tt*preds2tt*smear			predstt[predstt<0] = 0		}, error = function(e) {			assign('fittrain', FALSE, envir=.GlobalEnv) # if we hit an error in predictions, we can't calculate performance stats			mywarn <- paste('Error in predicting to test data for', i, sp, ':', e)			assign('allwarnings', c(get('allwarnings', envir=.GlobalEnv), mywarn), envir=.GlobalEnv) # these assigns outside the local scope are poor form in R. But not sure how else to do it here...			warning(mywarn)		})	}	# fill in diagnostics	modeldiag$sppocean[i] = sp	modeldiag$npres[i] = sum(spdata$presfit)	if(fittrain){		modeldiag$npres.tr[i] = sum(spdata$presfit[traininds])		modeldiag$npres.te[i] = sum(spdata$presfit[testinds])	}	modeldiag$ntot[i] = dim(spdata)[1]	# fill in myregions and myseasons too? would be useful for projections	# calculate performance using AUC (in part using ROCR)	preds1.rocr = prediction(predictions=as.numeric(preds1), labels=spdata$presfit)	modeldiag$auc[i] = performance(preds1.rocr, 'auc')@y.values[[1]] # area under the ROC curve	if(length(testindsp)>0 & fittrain){ # need presences in the test dataset		preds1tt.rocr = prediction(predictions=as.numeric(preds1tt), labels=spdata$presfit[testinds])		modeldiag$auc.tt[i] = performance(preds1tt.rocr, 'auc')@y.values[[1]] #	}	# true skill statistic	a = performance(preds1.rocr, 'tpr')@y.values[[1]] # true positive	b = performance(preds1.rocr, 'fnr')@y.values[[1]] # false negative	c = performance(preds1.rocr, 'fpr')@y.values[[1]] # false pos	d = performance(preds1.rocr, 'tnr')@y.values[[1]] # true neg	modeldiag$tss[i] = 	max((a*d - b*c)/((a+c)*(b+d)), na.rm=TRUE)	if(length(testindsp)>0 & fittrain){ # need presences in the test dataset		preds1tt.rocr = prediction(predictions=as.numeric(preds1tt), labels=spdata$presfit[testinds])		a = performance(preds1tt.rocr, 'tpr')@y.values[[1]] # true positive		b = performance(preds1tt.rocr, 'fnr')@y.values[[1]] # false negative		c = performance(preds1tt.rocr, 'fpr')@y.values[[1]] # false pos		d = performance(preds1tt.rocr, 'tnr')@y.values[[1]] # true neg		modeldiag$tss.tt[i] = max((a*d - b*c)/((a+c)*(b+d)), na.rm=TRUE)	}	modeldiag$r2.biomass[i] = cor(log(preds2[spdata$presfit]), spdata$logwtcpue[spdata$presfit])^2 # correlation of log(biomass) where present	if(length(testindsp)>0 & fittrain) modeldiag$r2.biomass.tt[i] = cor(preds2tt[which(testinds %in% testindsp)], spdata$logwtcpue[testindsp])^2 # only if presences exist in the test dataset	modeldiag$r2.all[i] = cor(preds, spdata$wtcpue)^2 # overall biomass correlation	if(length(testindsp)>0 & fittrain) modeldiag$r2.all.tt[i] = cor(predstt, spdata$wtcpue[testinds])^2 # overall biomass correlation. only makes sense to do this if the species is present at least once in the testing dataset	modeldiag$dev.pres[i] = summary(mygam1)$dev.expl	modeldiag$dev.biomass[i] = summary(mygam2)$dev.expl#
	#Compare to models without temperature to ultimately calculation %explained by temp terms	modeldiag$dev.pres.null[i] = summary(mygam1null)$dev.expl	modeldiag$dev.biomass.null[i] = summary(mygam2null)$dev.expl	# Some metrics at a spatially aggregated level (1x1deg square) (by year) may be more informative:	test<-cbind(spdata,preds1,preds)	t1<-tapply(test$preds1,list(test$year,test$cs1),mean) #average predicted p(occur)	t2<-tapply(test$presfit,list(test$year,test$cs1),mean) #proportion of hauls with presence	t3<-tapply(test$preds,list(test$year,test$cs1),mean) #average predicted abundance	t4<-tapply(test$wtcpue,list(test$year,test$cs1),mean) #average observed abundance	presr2<-round(cor(stack(as.data.frame(t2))[,1],stack(as.data.frame(t1))[,1],use="p")^2,2)	abunr2<-round(cor(stack(as.data.frame(t4))[,1],(stack(as.data.frame(t3))[,1]),use="p")^2,2)	#par(mfrow=c(1,2))	#plot(stack(as.data.frame(t2))[,1],stack(as.data.frame(t1))[,1],xlab="Proportion of hauls with species present (by 1 deg square)",ylab="Mean predicted probability of occurrence", cex=0.5,main=sp)	#mtext(paste("r^2 =",presr2))	#plot(stack(as.data.frame(t4))[,1],(stack(as.data.frame(t3))[,1]),xlab="Average log(WTCPUE) (by 1 deg square)",ylab="Average predicted log(WTCPUE)", cex=0.5,main=sp)	#mtext(paste("r^2 =",abunr2))	modeldiag$r2.pres.1deg[i]<-presr2	modeldiag$r2.abun.1deg[i]<-abunr2	#Also save average biomassmean for each region (across all years) to use in later predictions.	avemeanbiomass<-apply(ave.catch.wt,2,mean,na.rm=T) #ave.catch.wt from far above	####################################################	#### Save models for later projections	####################################################	mods = list(mygam1=mygam1, mygam2 = mygam2)#
	sp <- gsub('/', '', sp) # would mess up saving the file#
	if(Sys.info()["nodename"] == "pinsky-macbookair"){		save(mods, avemeanbiomass, myregions, file=paste('../CEmodels/CEmods_',runname, '_', sp, '_', Sys.Date(), '.RData', sep='')) # ~2mb file	}	if(Sys.info()["nodename"] == "amphiprion.deenr.rutgers.edu"){		save(mods, avemeanbiomass, myregions, file=paste('../CEmodels/CEmods_',runname, '_', sp, '_', Sys.Date(), '.RData', sep='')) # ~2mb file	}	if(Sys.info()["user"] == "lauren"){		save(mods, avemeanbiomass, myregions, file=paste('output/CEmodels/CEmods_',runname, '_', sp, '_', Sys.Date(), '.RData', sep='')) # ~2mb file	}	#think about figures to output - thermal response curves? spatial prediction by 1 deg square?	#think about other data to save - number of pres/abs by region (?) }dev.off()save(modeldiag,file=paste("output/modeldiag_",runname,".Rdata",sep=""))write.csv(modeldiag, file=paste("output/modeldiag_",runname,".csv",sep=""))write.csv(allwarnings, file=paste('output/warnings_', runname, '.csv', sep=''))
print(paste(length(allspp), 'models to fit'))
8/20 * 551
8/20 * 551/60
